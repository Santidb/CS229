{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6. Neural Network",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi9JACGfb39h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOgFpRnSu8mk",
        "outputId": "56bbfbfa-8be5-4c2f-a616-78147759c20b"
      },
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n",
        "FOLDERNAME = 'CS229/Project/'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "%cd drive/My\\ Drive/$FOLDERNAME"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/CS229/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XmdRdykvAEp"
      },
      "source": [
        "# Baseline packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Custom packages\n",
        "from util import load_dataset\n",
        "from util import place_bets\n",
        "from util import evaluate_bets\n",
        "from custom_loss import custom_loss\n",
        "\n",
        "# Neural Network packages\n",
        "from keras.layers import BatchNormalization, Dense, Input, Dropout\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "pd.set_option('display.max_rows', 300)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvNwPvNvvGHB"
      },
      "source": [
        "# Training\n",
        "x_train = load_dataset(\"Load_Data/x_train.csv\", intercept=True)\n",
        "y_train = load_dataset(\"Load_Data/y_train.csv\").to_numpy().flatten()\n",
        "\n",
        "# Validation\n",
        "x_val = load_dataset(\"Load_Data/x_val.csv\", intercept=True)\n",
        "y_val = load_dataset(\"Load_Data/y_val.csv\").to_numpy().flatten()\n",
        "\n",
        "# Test\n",
        "x_test = load_dataset(\"Load_Data/x_test.csv\", intercept=True)\n",
        "y_test = load_dataset(\"Load_Data/y_test.csv\").to_numpy().flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqazgSGZBy2f"
      },
      "source": [
        "def generate_nnlabels(y, x):\n",
        "  \"\"\" Generate labels for use in the neural network model of the form [Win_home, Win_away, No Bet, Odds_home, Odds_away]\n",
        "\n",
        "  Args:\n",
        "    y: vector with 0 if win_away and 1 if win_home. Shape (num_bets, )\n",
        "    x: feature vector containing odds_home and odds_away. Shape (num_bets, dim)\n",
        "  \"\"\"\n",
        "  n = len(y)\n",
        "  matrix = np.zeros((n, 5))\n",
        "\n",
        "  matrix[:, 0] = y\n",
        "  matrix[:, 1] = 1-y\n",
        "  # matrix[:,2] is already zeros\n",
        "  matrix[:, 3] = x['Odds_Home'].reset_index(drop=True)\n",
        "  matrix[:, 4] = x['Odds_Away'].reset_index(drop=True)\n",
        "  \n",
        "  return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0LcDF3y2irJ"
      },
      "source": [
        "# Modifying y vectors to be of the form [Win_home, Win_away, No Bet, Odds_home, Odds_away]\n",
        "ynn_train = generate_nnlabels(y_train, x_train)\n",
        "ynn_val = generate_nnlabels(y_val, x_val)\n",
        "ynn_test = generate_nnlabels(y_test, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SMQG-BuvIfI"
      },
      "source": [
        "# Neural network model adapted from Malafosse, Charles (https://towardsdatascience.com/machine-learning-for-sports-betting-not-a-basic-classification-problem-b42ae4900782#:~:text=Sports%20betting%20is%20one%20of,and%20specifically%20classification%20neural%20networks.&text=Nonetheless%2C%20classic%20classification%20models%20are,network%20to%20achieve%20better%20profitability.)\n",
        "\n",
        "def odds_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    The function implements the custom loss function\n",
        "    \n",
        "    Args:\n",
        "      true: a vector of dimension batch_size, 5. A label encoded version of the output and the backp1_a and backp1_b\n",
        "      pred: a vector of probabilities of dimension batch_size , 3.\n",
        "    \n",
        "    Returns: \n",
        "      Loss value\n",
        "    \"\"\"\n",
        "    win_home_team = y_true[:, 0:1]\n",
        "    win_away = y_true[:, 1:2]\n",
        "    no_bet = y_true[:, 2:3]\n",
        "    odds_a = y_true[:, 3:4]\n",
        "    odds_b = y_true[:, 4:5]\n",
        "\n",
        "    gain_loss_vector = K.concatenate([win_home_team * (odds_a - 1) + (1 - win_home_team) * -1,  # payoff when we say home team is going to win\n",
        "      win_away * (odds_b - 1) + (1 - win_away) * -1,                                            # payoff when we say away team is going to win\n",
        "      K.zeros_like(odds_a)], axis=1)                                                            # payoff when we do not bet\n",
        "    return -1 * K.mean(K.sum(gain_loss_vector * y_pred, axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKleK00RwKng"
      },
      "source": [
        "# Defining model we will run\n",
        "def get_model(input_dim, output_dim, base=1000, multiplier=0.25, p=0.2):\n",
        "    inputs = Input(shape=(input_dim,))\n",
        "    l = BatchNormalization()(inputs)\n",
        "    l = Dropout(p)(l)\n",
        "    n = base\n",
        "    l = Dense(n, activation='relu')(l)\n",
        "    l = BatchNormalization()(l)\n",
        "    l = Dropout(p)(l)\n",
        "    n = int(n * multiplier)\n",
        "    l = Dense(n, activation='relu')(l)\n",
        "    l = BatchNormalization()(l)\n",
        "    l = Dropout(p)(l)\n",
        "    n = int(n * multiplier)\n",
        "    l = Dense(n, activation='relu')(l)\n",
        "    outputs = Dense(output_dim, activation='softmax')(l)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='Nadam', loss=odds_loss)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXOUUqYPHQE0"
      },
      "source": [
        "input_dim = x_train.shape[1]\n",
        "output_dim = 3              # Home win, Away win, No Bet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuT4eaQiHBQc",
        "outputId": "f7c7e2d8-f6c5-4e35-ee8d-d71249a5b1cf"
      },
      "source": [
        "neurons = [100, 150, 200]\n",
        "multiplier = [0.50, 0.75]\n",
        "p = [0.3, 0.5]\n",
        "results_dic = {}\n",
        "\n",
        "\n",
        "for neuron in neurons:\n",
        "  for mult in multiplier:\n",
        "    for dropout in p:\n",
        "      model = get_model(input_dim, output_dim, neuron, mult, dropout)\n",
        "      history = model.fit(x_train, ynn_train, validation_data=(x_val, ynn_val),\n",
        "                epochs=200, batch_size=5000, callbacks=[EarlyStopping(patience=25),ModelCheckpoint('odds_loss.hdf5',save_best_only=True)])\n",
        "      results_dic[(neuron, mult, dropout)] = [model.evaluate(x_train, ynn_train), model.evaluate(x_val, ynn_val)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.0523 - val_loss: 0.0761\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.1848 - val_loss: 0.0705\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2683 - val_loss: 0.0552\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.3156 - val_loss: 0.0363\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.3509 - val_loss: 0.0257\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.3756 - val_loss: 0.0469\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.3945 - val_loss: 0.0469\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 2s 42ms/step - loss: -0.4087 - val_loss: 0.0419\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4197 - val_loss: 0.0498\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4272 - val_loss: 0.0357\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4315 - val_loss: 0.0428\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 2s 42ms/step - loss: -0.4393 - val_loss: 0.0405\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4438 - val_loss: 0.0286\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 2s 42ms/step - loss: -0.4465 - val_loss: 0.0389\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.4523 - val_loss: 0.0358\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.4537 - val_loss: 0.0543\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 2s 42ms/step - loss: -0.4558 - val_loss: 0.0461\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4642 - val_loss: 0.0478\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4599 - val_loss: 0.0679\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4641 - val_loss: 0.0697\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4639 - val_loss: 0.0701\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4687 - val_loss: 0.0599\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 2s 42ms/step - loss: -0.4726 - val_loss: 0.0800\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 2s 42ms/step - loss: -0.4722 - val_loss: 0.0684\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.4775 - val_loss: 0.0615\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.4765 - val_loss: 0.0710\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 2s 45ms/step - loss: -0.4756 - val_loss: 0.0770\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 2s 45ms/step - loss: -0.4810 - val_loss: 0.0678\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 2s 45ms/step - loss: -0.4770 - val_loss: 0.0705\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.4767 - val_loss: 0.0701\n",
            "6613/6613 [==============================] - 6s 972us/step - loss: -0.7844\n",
            "1461/1461 [==============================] - 1s 951us/step - loss: 0.0701\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: 0.0058 - val_loss: 0.0414\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 2s 45ms/step - loss: -0.0819 - val_loss: 0.0239\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 2s 46ms/step - loss: -0.1406 - val_loss: 0.0117\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 2s 45ms/step - loss: -0.1596 - val_loss: 0.0073\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.1733 - val_loss: 0.0195\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.1863 - val_loss: 0.0367\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.1943 - val_loss: 0.0433\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.1992 - val_loss: 0.0389\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2098 - val_loss: 0.0435\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2122 - val_loss: 0.0537\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2147 - val_loss: 0.0488\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2197 - val_loss: 0.0506\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2230 - val_loss: 0.0612\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2260 - val_loss: 0.0509\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.2301 - val_loss: 0.0470\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.2349 - val_loss: 0.0478\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.2343 - val_loss: 0.0362\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2382 - val_loss: 0.0412\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.2415 - val_loss: 0.0395\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.2439 - val_loss: 0.0333\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2435 - val_loss: 0.0287\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.2461 - val_loss: 0.0091\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2515 - val_loss: 0.0232\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2508 - val_loss: 0.0299\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 2s 43ms/step - loss: -0.2502 - val_loss: 0.0341\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2546 - val_loss: 0.0344\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2548 - val_loss: 0.0380\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2534 - val_loss: 0.0207\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 2s 44ms/step - loss: -0.2602 - val_loss: 0.0141\n",
            "6613/6613 [==============================] - 7s 992us/step - loss: -0.6110\n",
            "1461/1461 [==============================] - 1s 1ms/step - loss: 0.0141\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.1046 - val_loss: 0.0372\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.2577 - val_loss: 0.0324\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.3207 - val_loss: 0.0293\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.3525 - val_loss: 0.0149\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.3736 - val_loss: 0.0383\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.3908 - val_loss: 0.0152\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.4017 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.4118 - val_loss: -0.0092\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4197 - val_loss: 0.0037\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4311 - val_loss: -0.0045\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4354 - val_loss: -0.0148\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4402 - val_loss: -0.0123\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.4450 - val_loss: -0.0186\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4496 - val_loss: 0.0048\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.4519 - val_loss: 0.0175\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4523 - val_loss: 0.0108\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4593 - val_loss: -7.1031e-04\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4667 - val_loss: -0.0029\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.4638 - val_loss: 0.0069\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4680 - val_loss: 0.0079\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4688 - val_loss: 6.4726e-04\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 2s 50ms/step - loss: -0.4666 - val_loss: 0.0051\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4720 - val_loss: -6.9203e-04\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4750 - val_loss: 0.0107\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4730 - val_loss: -0.0053\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4749 - val_loss: -0.0088\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4780 - val_loss: -0.0103\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4791 - val_loss: -0.0165\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.4777 - val_loss: -0.0111\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4794 - val_loss: -0.0169\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4843 - val_loss: -6.9118e-04\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 2s 50ms/step - loss: -0.4851 - val_loss: 0.0052\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4868 - val_loss: 0.0091\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.4860 - val_loss: 0.0336\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4910 - val_loss: 0.0148\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4916 - val_loss: -0.0043\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4895 - val_loss: 0.0310\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 2s 51ms/step - loss: -0.4973 - val_loss: 0.0458\n",
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.8037\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: 0.0458\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0213 - val_loss: 0.0535\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 2s 55ms/step - loss: -0.1048 - val_loss: 0.0155\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.1472 - val_loss: -0.0024\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.1698 - val_loss: 0.0105\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.1763 - val_loss: 0.0107\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.1930 - val_loss: 0.0329\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.1956 - val_loss: 0.0456\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2018 - val_loss: 0.0445\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2075 - val_loss: 0.0574\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2103 - val_loss: 0.0518\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2181 - val_loss: 0.0445\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 3s 60ms/step - loss: -0.2203 - val_loss: 0.0545\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.2273 - val_loss: 0.0517\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 2s 55ms/step - loss: -0.2263 - val_loss: 0.0490\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2339 - val_loss: 0.0537\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 2s 55ms/step - loss: -0.2396 - val_loss: 0.0625\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 2s 56ms/step - loss: -0.2384 - val_loss: 0.0638\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 2s 55ms/step - loss: -0.2454 - val_loss: 0.0721\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.2401 - val_loss: 0.0552\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2454 - val_loss: 0.0514\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.2509 - val_loss: 0.0565\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.2450 - val_loss: 0.0472\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2543 - val_loss: 0.0403\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 2s 54ms/step - loss: -0.2544 - val_loss: 0.0730\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2541 - val_loss: 0.0577\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 2s 53ms/step - loss: -0.2582 - val_loss: 0.0419\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.2626 - val_loss: 0.0458\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 2s 52ms/step - loss: -0.2569 - val_loss: 0.0417\n",
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.6131\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: 0.0417\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.1245 - val_loss: 0.0316\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2789 - val_loss: 0.0159\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.3456 - val_loss: -0.0012\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.3814 - val_loss: -2.8344e-05\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.4075 - val_loss: -4.0912e-04\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.4214 - val_loss: 0.0100\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.4365 - val_loss: 0.0217\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4422 - val_loss: 0.0490\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.4542 - val_loss: 0.0132\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.4547 - val_loss: 0.0178\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4619 - val_loss: 0.0110\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 3s 68ms/step - loss: -0.4649 - val_loss: -0.0041\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4678 - val_loss: 0.0028\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.4755 - val_loss: 0.0257\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4793 - val_loss: 0.0263\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4827 - val_loss: 0.0198\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4838 - val_loss: 0.0275\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.4874 - val_loss: 0.0107\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.4903 - val_loss: 0.0179\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.4905 - val_loss: 0.0015\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 3s 65ms/step - loss: -0.4935 - val_loss: 0.0275\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.4959 - val_loss: 0.0279\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4986 - val_loss: 0.0112\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4991 - val_loss: 0.0025\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5002 - val_loss: 0.0104\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.4979 - val_loss: 0.0241\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5022 - val_loss: 0.0241\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5043 - val_loss: 0.0520\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5087 - val_loss: 0.0114\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5060 - val_loss: 0.0182\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5063 - val_loss: 0.0062\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5129 - val_loss: -0.0023\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5132 - val_loss: 0.0015\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5123 - val_loss: 0.0075\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5152 - val_loss: -0.0014\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5168 - val_loss: 9.0881e-04\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.5186 - val_loss: 0.0184\n",
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.8029\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: 0.0184\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 3s 73ms/step - loss: -0.0145 - val_loss: 0.0425\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.1132 - val_loss: 0.0214\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.1633 - val_loss: 0.0105\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.1808 - val_loss: 0.0074\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.1955 - val_loss: 0.0090\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2013 - val_loss: 0.0364\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2125 - val_loss: 0.0564\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2205 - val_loss: 0.0252\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2265 - val_loss: 0.0315\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2319 - val_loss: 0.0474\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2364 - val_loss: 0.0411\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2396 - val_loss: 0.0122\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2470 - val_loss: 0.0098\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2443 - val_loss: 0.0083\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2473 - val_loss: 0.0076\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 3s 68ms/step - loss: -0.2519 - val_loss: -0.0125\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2550 - val_loss: -0.0178\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2586 - val_loss: -0.0057\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2620 - val_loss: 0.0034\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2586 - val_loss: -0.0056\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2640 - val_loss: -0.0020\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2613 - val_loss: -0.0142\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 3s 70ms/step - loss: -0.2680 - val_loss: -0.0203\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2685 - val_loss: -0.0137\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2691 - val_loss: -0.0170\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 3s 69ms/step - loss: -0.2726 - val_loss: -0.0277\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2716 - val_loss: -0.0060\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2705 - val_loss: -0.0175\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2758 - val_loss: -0.0061\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2749 - val_loss: 0.0143\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2791 - val_loss: -0.0030\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2766 - val_loss: -0.0183\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2765 - val_loss: -0.0079\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2735 - val_loss: -0.0186\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2775 - val_loss: -0.0043\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2811 - val_loss: -0.0110\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2805 - val_loss: 0.0073\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2868 - val_loss: -0.0099\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 3s 65ms/step - loss: -0.2834 - val_loss: 0.0098\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2848 - val_loss: 0.0045\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2847 - val_loss: 0.0205\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2832 - val_loss: 0.0191\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2874 - val_loss: 0.0131\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2911 - val_loss: 0.0022\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.2850 - val_loss: 0.0075\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2907 - val_loss: 0.0156\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 3s 65ms/step - loss: -0.2877 - val_loss: 4.0624e-04\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2909 - val_loss: 0.0096\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.2918 - val_loss: 0.0194\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2911 - val_loss: 0.0328\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.2945 - val_loss: 0.0219\n",
            "6613/6613 [==============================] - 9s 1ms/step - loss: -0.6927\n",
            "1461/1461 [==============================] - 2s 2ms/step - loss: 0.0219\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 4s 86ms/step - loss: -0.1281 - val_loss: 0.0448\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.3010 - val_loss: 0.0309\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.3698 - val_loss: 0.0179\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.4077 - val_loss: 0.0051\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.4282 - val_loss: -0.0145\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.4404 - val_loss: 0.0393\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.4519 - val_loss: 0.0236\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.4581 - val_loss: 0.0440\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.4654 - val_loss: 0.0449\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.4703 - val_loss: 0.0410\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.4710 - val_loss: 0.0409\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 3s 73ms/step - loss: -0.4760 - val_loss: 0.0550\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.4810 - val_loss: 0.0471\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.4817 - val_loss: 0.0436\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 3s 73ms/step - loss: -0.4846 - val_loss: 0.0299\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 3s 73ms/step - loss: -0.4905 - val_loss: 0.0241\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.4923 - val_loss: 0.0538\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 3s 72ms/step - loss: -0.4955 - val_loss: 0.0615\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 3s 73ms/step - loss: -0.4972 - val_loss: 0.0836\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 3s 72ms/step - loss: -0.5004 - val_loss: 0.0828\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 3s 72ms/step - loss: -0.5017 - val_loss: 0.0442\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.5047 - val_loss: 0.0634\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 3s 73ms/step - loss: -0.5075 - val_loss: 0.0562\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 3s 73ms/step - loss: -0.5069 - val_loss: 0.0622\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.5115 - val_loss: 0.0475\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.5075 - val_loss: 0.0522\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.5125 - val_loss: 0.0633\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 3s 76ms/step - loss: -0.5074 - val_loss: 0.0695\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 3s 76ms/step - loss: -0.5136 - val_loss: 0.0784\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.5169 - val_loss: 0.0519\n",
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.8173\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: 0.0519\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 4s 86ms/step - loss: -0.0432 - val_loss: 0.0490\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 3s 76ms/step - loss: -0.1431 - val_loss: 0.0071\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.1728 - val_loss: -0.0033\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 3s 76ms/step - loss: -0.1883 - val_loss: -0.0038\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.1965 - val_loss: 0.0034\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2110 - val_loss: 0.0210\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2129 - val_loss: 0.0268\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2191 - val_loss: 0.0177\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2263 - val_loss: 0.0343\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2317 - val_loss: 0.0207\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2351 - val_loss: 0.0191\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2353 - val_loss: 0.0126\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.2476 - val_loss: -0.0152\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.2473 - val_loss: -0.0195\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 3s 76ms/step - loss: -0.2528 - val_loss: -0.0060\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.2558 - val_loss: -0.0310\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2531 - val_loss: -0.0235\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2534 - val_loss: -0.0204\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2621 - val_loss: -0.0242\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2617 - val_loss: -0.0295\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.2672 - val_loss: -0.0349\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2648 - val_loss: -0.0351\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 3s 76ms/step - loss: -0.2700 - val_loss: -0.0476\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2701 - val_loss: -0.0438\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2712 - val_loss: -0.0343\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2745 - val_loss: -0.0388\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2749 - val_loss: -0.0353\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2744 - val_loss: -0.0286\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2738 - val_loss: -0.0255\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2801 - val_loss: -0.0275\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2791 - val_loss: -0.0326\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2842 - val_loss: -0.0294\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2820 - val_loss: -0.0336\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2813 - val_loss: -0.0258\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 3s 76ms/step - loss: -0.2861 - val_loss: -0.0277\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 3s 76ms/step - loss: -0.2821 - val_loss: -0.0218\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2852 - val_loss: -0.0290\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2841 - val_loss: -0.0269\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2855 - val_loss: -0.0220\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2903 - val_loss: -0.0195\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2918 - val_loss: -0.0137\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2890 - val_loss: -0.0230\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2908 - val_loss: -0.0152\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2931 - val_loss: -0.0273\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2911 - val_loss: 7.6936e-04\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2930 - val_loss: -4.8441e-04\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 3s 75ms/step - loss: -0.2934 - val_loss: -0.0260\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: -0.2968 - val_loss: -0.0179\n",
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.6729\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: -0.0179\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 4s 89ms/step - loss: -0.1378 - val_loss: 0.0628\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.3114 - val_loss: 0.0675\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 4s 83ms/step - loss: -0.3814 - val_loss: 0.0599\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.4092 - val_loss: 0.0721\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.4362 - val_loss: 0.0863\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.4518 - val_loss: 0.0603\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.4598 - val_loss: 0.0726\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.4705 - val_loss: 0.0799\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.4740 - val_loss: 0.0723\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.4813 - val_loss: 0.0836\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.4876 - val_loss: 0.0679\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 4s 83ms/step - loss: -0.4892 - val_loss: 0.0547\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.4957 - val_loss: 0.0682\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.4988 - val_loss: 0.0572\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.4953 - val_loss: 0.0748\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 4s 83ms/step - loss: -0.5022 - val_loss: 0.0513\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5081 - val_loss: 0.0524\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5069 - val_loss: 0.0340\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.5116 - val_loss: 0.0473\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 4s 84ms/step - loss: -0.5121 - val_loss: 0.0308\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.5118 - val_loss: 0.0190\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5136 - val_loss: 0.0111\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5174 - val_loss: 0.0190\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.5171 - val_loss: 0.0392\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5229 - val_loss: 0.0272\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 4s 84ms/step - loss: -0.5251 - val_loss: 0.0107\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5249 - val_loss: 0.0204\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5296 - val_loss: 0.0417\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 4s 84ms/step - loss: -0.5295 - val_loss: 0.0085\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.5275 - val_loss: 0.0180\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.5264 - val_loss: 0.0313\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 4s 84ms/step - loss: -0.5275 - val_loss: 0.0049\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5313 - val_loss: 0.0272\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5286 - val_loss: 0.0307\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5383 - val_loss: 0.0141\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5318 - val_loss: 0.0242\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 4s 86ms/step - loss: -0.5371 - val_loss: 4.9182e-04\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5398 - val_loss: -0.0051\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.5379 - val_loss: -0.0068\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5375 - val_loss: 0.0147\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.5390 - val_loss: 0.0257\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5440 - val_loss: 0.0125\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5441 - val_loss: 0.0466\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 4s 87ms/step - loss: -0.5455 - val_loss: 0.0336\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5440 - val_loss: 0.0557\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5433 - val_loss: 0.0520\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5519 - val_loss: 0.0542\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5452 - val_loss: 0.0564\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5506 - val_loss: 0.0324\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.5491 - val_loss: 0.0422\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5496 - val_loss: 0.0380\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5511 - val_loss: 0.0434\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.5496 - val_loss: 0.0418\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5529 - val_loss: 0.0489\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5544 - val_loss: 0.0387\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.5549 - val_loss: 0.0178\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5571 - val_loss: 0.0549\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5542 - val_loss: 0.0256\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5584 - val_loss: 0.0197\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.5580 - val_loss: 0.0372\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5604 - val_loss: 0.0363\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5610 - val_loss: 0.0447\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5584 - val_loss: 0.0503\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.5552 - val_loss: 0.0625\n",
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.8470\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: 0.0625\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 4s 91ms/step - loss: -0.0267 - val_loss: 0.0509\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 3s 81ms/step - loss: -0.1408 - val_loss: 0.0230\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 3s 81ms/step - loss: -0.1821 - val_loss: 0.0029\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.1979 - val_loss: -0.0010\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.2079 - val_loss: -0.0038\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2205 - val_loss: 0.0067\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2294 - val_loss: -0.0179\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 4s 82ms/step - loss: -0.2389 - val_loss: -0.0271\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2419 - val_loss: -0.0066\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.2521 - val_loss: -0.0242\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 4s 84ms/step - loss: -0.2524 - val_loss: -0.0396\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2575 - val_loss: -0.0324\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2604 - val_loss: -0.0271\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2650 - val_loss: -0.0305\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 4s 83ms/step - loss: -0.2656 - val_loss: -0.0591\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2689 - val_loss: -0.0379\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2701 - val_loss: -0.0507\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2763 - val_loss: -0.0275\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2760 - val_loss: -0.0187\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2767 - val_loss: -0.0240\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.2786 - val_loss: -0.0210\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2761 - val_loss: -0.0436\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2769 - val_loss: -0.0516\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 4s 87ms/step - loss: -0.2834 - val_loss: -0.0382\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 8s 176ms/step - loss: -0.2831 - val_loss: -0.0452\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 5s 123ms/step - loss: -0.2861 - val_loss: -0.0236\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2854 - val_loss: -0.0408\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2894 - val_loss: -0.0498\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.2871 - val_loss: -0.0454\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.2972 - val_loss: -0.0236\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 3s 77ms/step - loss: -0.2916 - val_loss: -0.0389\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2911 - val_loss: -0.0398\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2985 - val_loss: -0.0414\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2980 - val_loss: -0.0385\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.3017 - val_loss: -0.0311\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 3s 78ms/step - loss: -0.2961 - val_loss: -0.0491\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2985 - val_loss: -0.0242\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 3s 79ms/step - loss: -0.2992 - val_loss: -0.0342\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 3s 81ms/step - loss: -0.3005 - val_loss: -0.0417\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 3s 80ms/step - loss: -0.3050 - val_loss: -0.0252\n",
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.7077\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: -0.0252\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 4s 103ms/step - loss: -0.1711 - val_loss: 0.0390\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 4s 97ms/step - loss: -0.3370 - val_loss: 0.0383\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 4s 96ms/step - loss: -0.3934 - val_loss: 0.0335\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.4229 - val_loss: 0.0544\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.4418 - val_loss: 0.0381\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.4585 - val_loss: 0.0524\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 4s 99ms/step - loss: -0.4678 - val_loss: 0.0243\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.4764 - val_loss: 0.0439\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.4773 - val_loss: 0.0479\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 4s 97ms/step - loss: -0.4835 - val_loss: 0.0334\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 4s 97ms/step - loss: -0.4921 - val_loss: 0.0499\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.4937 - val_loss: 0.0465\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.4967 - val_loss: 0.0470\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.4973 - val_loss: 0.0573\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.4997 - val_loss: 0.0374\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5037 - val_loss: 0.0497\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.5077 - val_loss: 0.0457\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5047 - val_loss: 0.0570\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.5104 - val_loss: 0.0597\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.5135 - val_loss: 0.0610\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5138 - val_loss: 0.0495\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.5155 - val_loss: 0.0397\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.5141 - val_loss: 0.0380\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5176 - val_loss: 0.0388\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.5199 - val_loss: 0.0485\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5176 - val_loss: 0.0588\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.5195 - val_loss: 0.0657\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5249 - val_loss: 0.0786\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5230 - val_loss: 0.0705\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.5305 - val_loss: 0.0679\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5286 - val_loss: 0.0631\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.5332 - val_loss: 0.0361\n",
            "6613/6613 [==============================] - 8s 1ms/step - loss: -0.8159\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: 0.0361\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 5s 106ms/step - loss: -0.0658 - val_loss: 0.0349\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.1585 - val_loss: 0.0104\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 4s 97ms/step - loss: -0.1882 - val_loss: -0.0030\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 4s 96ms/step - loss: -0.2000 - val_loss: -0.0088\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.2107 - val_loss: -0.0065\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.2253 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.2344 - val_loss: 0.0140\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.2354 - val_loss: 0.0243\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.2455 - val_loss: 0.0359\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 4s 93ms/step - loss: -0.2492 - val_loss: 0.0395\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.2511 - val_loss: 0.0227\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.2637 - val_loss: -7.4273e-05\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.2598 - val_loss: 0.0126\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.2684 - val_loss: -0.0042\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 4s 96ms/step - loss: -0.2680 - val_loss: 0.0188\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.2715 - val_loss: 0.0449\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.2740 - val_loss: 0.0057\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.2736 - val_loss: 0.0158\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 4s 93ms/step - loss: -0.2803 - val_loss: 0.0190\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.2823 - val_loss: -0.0017\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 4s 94ms/step - loss: -0.2821 - val_loss: -0.0086\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 4s 96ms/step - loss: -0.2816 - val_loss: 0.0133\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 4s 96ms/step - loss: -0.2860 - val_loss: 0.0291\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 4s 99ms/step - loss: -0.2910 - val_loss: 0.0321\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 4s 97ms/step - loss: -0.2869 - val_loss: -0.0073\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 4s 96ms/step - loss: -0.2911 - val_loss: 0.0186\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 4s 95ms/step - loss: -0.2942 - val_loss: 0.0187\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 4s 96ms/step - loss: -0.2920 - val_loss: 0.0258\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 4s 97ms/step - loss: -0.2919 - val_loss: 3.7956e-04\n",
            "6613/6613 [==============================] - 8s 1ms/step - loss: -0.6806\n",
            "1461/1461 [==============================] - 2s 1ms/step - loss: 3.7953e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_KIpmrjcNq0",
        "outputId": "44a8c39d-f0ba-4816-91ad-74a26511ea73"
      },
      "source": [
        "results_dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(100, 0.5, 0.3): [-0.7843984961509705, 0.07008127123117447],\n",
              " (100, 0.5, 0.5): [-0.6109845638275146, 0.014061084017157555],\n",
              " (100, 0.75, 0.3): [-0.8037264943122864, 0.0458122119307518],\n",
              " (100, 0.75, 0.5): [-0.6131053566932678, 0.041706256568431854],\n",
              " (150, 0.5, 0.3): [-0.8028547763824463, 0.01836675964295864],\n",
              " (150, 0.5, 0.5): [-0.6926648616790771, 0.02187945321202278],\n",
              " (150, 0.75, 0.3): [-0.8173401355743408, 0.051867857575416565],\n",
              " (150, 0.75, 0.5): [-0.6729459166526794, -0.017919056117534637],\n",
              " (200, 0.5, 0.3): [-0.8469763994216919, 0.06254413723945618],\n",
              " (200, 0.5, 0.5): [-0.7077128887176514, -0.025192582979798317],\n",
              " (200, 0.75, 0.3): [-0.8159429430961609, 0.036074016243219376],\n",
              " (200, 0.75, 0.5): [-0.6806380748748779, 0.0003795288794208318]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8luKEF8dG7X"
      },
      "source": [
        "### Obtaining best performing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eyyxqWtb5Mm"
      },
      "source": [
        "# Obtaining spec of best-performing model on the validation data\n",
        "counter = 0\n",
        "for spec, results in results_dic.items():\n",
        "  if counter == 0:\n",
        "    best_spec = spec\n",
        "  elif spec[1] > best_spec:\n",
        "    best_spec = spec\n",
        "\n",
        "# Looking at best spec\n",
        "print(best_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQOW-qCA2cmA",
        "outputId": "fc7713b1-0d78-47d8-b031-4dd44d2a5397"
      },
      "source": [
        "# Running NN with best model\n",
        "best_model = get_model(input_dim, output_dim, 150, 0.75, 0.50)\n",
        "history = best_model.fit(x_train, ynn_train, validation_data=(x_val, ynn_val),\n",
        "          epochs=200, batch_size=5000, callbacks=[EarlyStopping(patience=25),ModelCheckpoint('odds_loss.hdf5',save_best_only=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "43/43 [==============================] - 3s 72ms/step - loss: 0.0029 - val_loss: 0.0383\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0162 - val_loss: 0.0246\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0305 - val_loss: 0.0121\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0358 - val_loss: 0.0090\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 3s 65ms/step - loss: -0.0374 - val_loss: 0.0012\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0403 - val_loss: -0.0019\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 3s 65ms/step - loss: -0.0419 - val_loss: -0.0033\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0415 - val_loss: -0.0050\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0450 - val_loss: -0.0065\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0470 - val_loss: 0.0019\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0472 - val_loss: -0.0021\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0499 - val_loss: -9.2843e-04\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 3s 67ms/step - loss: -0.0472 - val_loss: -0.0082\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0481 - val_loss: -0.0087\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0501 - val_loss: -0.0121\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0554 - val_loss: -0.0062\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0518 - val_loss: -5.3939e-04\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0524 - val_loss: 0.0042\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0560 - val_loss: 0.0051\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0530 - val_loss: -8.7216e-04\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0544 - val_loss: 0.0026\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0559 - val_loss: -0.0012\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0572 - val_loss: 0.0021\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0559 - val_loss: 0.0046\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0564 - val_loss: 0.0033\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 3s 65ms/step - loss: -0.0581 - val_loss: 0.0086\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 3s 66ms/step - loss: -0.0585 - val_loss: 0.0061\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0590 - val_loss: 0.0086\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0589 - val_loss: 0.0056\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0603 - val_loss: 0.0032\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0595 - val_loss: 0.0112\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0581 - val_loss: 0.0095\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0614 - val_loss: 0.0029\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0597 - val_loss: 0.0107\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0581 - val_loss: 0.0078\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0623 - val_loss: 0.0048\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0606 - val_loss: 0.0014\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0652 - val_loss: 0.0143\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0631 - val_loss: 0.0134\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0647 - val_loss: 0.0109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqcGxiLLIMrf",
        "outputId": "2865dccc-4022-45ae-f41f-29d6b446bde5"
      },
      "source": [
        "print('Training Loss : {}\\nValidation Loss : {}'.format(best_model.evaluate(x_train, ynn_train), best_model.evaluate(x_val, ynn_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.0813\n",
            "1461/1461 [==============================] - 1s 1ms/step - loss: 0.0109\n",
            "Training Loss : -0.08132106065750122\n",
            "Validation Loss : 0.010935821570456028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5QzqUyXedl5"
      },
      "source": [
        "### Calculating profit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr2OpBI5ehjD",
        "outputId": "8f1c0ce4-0f8f-4969-e0e3-b195b20f62dc"
      },
      "source": [
        "#  Calculate prediction probabilities in training sample\n",
        "pred_tr = best_model.predict(x_train)\n",
        "pred_tr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.37528977e-10, 9.55596566e-01, 4.44034189e-02],\n",
              "       [5.96988514e-10, 8.92633021e-01, 1.07366934e-01],\n",
              "       [5.56922342e-10, 9.03633535e-01, 9.63665172e-02],\n",
              "       ...,\n",
              "       [6.58079616e-14, 1.43618891e-07, 9.99999881e-01],\n",
              "       [4.91420123e-14, 7.75008928e-08, 9.99999881e-01],\n",
              "       [5.08601865e-15, 2.86958657e-09, 1.00000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89gNRmVye3qu"
      },
      "source": [
        "# Determine which bet is the winner \n",
        "bet_matrix_tr = np.zeros((pred_tr.shape))\n",
        "max_bet = np.argmax(pred_tr, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR3Bd-oMe2TO",
        "outputId": "82090a10-aa82-4279-cea6-5289d673bf21"
      },
      "source": [
        "# Create matrix with discrete decisions on which bet will be chosen\n",
        "n = bet_matrix_tr.shape[0]\n",
        "bet_matrix_tr[np.arange(n), max_bet] = 1\n",
        "bet_matrix_tr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_owmQ3-eiHIE",
        "outputId": "c53d07d5-88d8-4984-8da5-b9b3273252ab"
      },
      "source": [
        "# Calculate profit\n",
        "profit_train_strat = evaluate_bets(bet_matrix_tr, x_train['Odds_Home'], x_train['Odds_Away'], y_train)\n",
        "profit_train_strat.sum()\n",
        "\n",
        "print(f\"Model achieves profit of ${profit_train_strat.sum():.2f} on the training sample\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model achieves profit of $17242.26 on the training sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSA66VrqjyFh"
      },
      "source": [
        "On validation sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cwdgxg0j9Ql"
      },
      "source": [
        "# Predicting probabilities on validation sample\n",
        "pred_val = best_model.predict(x_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TZRBfs5kMe7"
      },
      "source": [
        "bet_matrix_val = np.zeros((pred_val.shape))\n",
        "max_bet_val = np.argmax(pred_val, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhjDzE_QkRue",
        "outputId": "9fbf0080-8f06-463d-a3cc-c5b0d3597505"
      },
      "source": [
        "# Create matrix with discrete decisions on which bet will be chosen\n",
        "n = bet_matrix_val.shape[0]\n",
        "bet_matrix_val[np.arange(n), max_bet_val] = 1\n",
        "bet_matrix_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BrOjSuwkWRs",
        "outputId": "32b61500-5885-416b-f092-3ce98e10571f"
      },
      "source": [
        "profit_val_strat = evaluate_bets(bet_matrix_val, x_val['Odds_Home'], x_val['Odds_Away'], y_val)\n",
        "\n",
        "print(f\"Model achieves profit of ${profit_val_strat.sum():.2f} on the validation sample\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model achieves profit of $-369.71 on the validation sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIOfbvwWlpf_"
      },
      "source": [
        "### Running experiments: Removing team from the X matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FgfzST8loNV"
      },
      "source": [
        "# Removing team from features to see if model is able to generalize better without teams\n",
        "x_train = x_train[['Intercept', 'Time_left', 'Spread', 'Odds_Home', 'Odds_Away', 'Initial_odds_home', 'Initial_odds_away', 'Q_2.0', 'Q_3.0', 'Q_4.0']]\n",
        "x_val = x_val[['Intercept', 'Time_left', 'Spread', 'Odds_Home', 'Odds_Away', 'Initial_odds_home', 'Initial_odds_away', 'Q_2.0', 'Q_3.0', 'Q_4.0']]\n",
        "x_test = x_test[['Intercept', 'Time_left', 'Spread', 'Odds_Home', 'Odds_Away', 'Initial_odds_home', 'Initial_odds_away', 'Q_2.0', 'Q_3.0', 'Q_4.0']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2hTOp3Yl1ai"
      },
      "source": [
        "input_dim = x_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6FWYuzMlunB",
        "outputId": "33d59694-303e-4b69-fa79-6310b50f85e9"
      },
      "source": [
        "# Running NN with best model\n",
        "best_model = get_model(input_dim, output_dim, 150, 0.75, 0.50)\n",
        "history = best_model.fit(x_train, ynn_train, validation_data=(x_val, ynn_val),\n",
        "          epochs=200, batch_size=5000, callbacks=[EarlyStopping(patience=25),ModelCheckpoint('odds_loss.hdf5',save_best_only=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "43/43 [==============================] - 3s 74ms/step - loss: 0.0057 - val_loss: 0.0277\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0202 - val_loss: 0.0206\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0268 - val_loss: 0.0094\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0324 - val_loss: 0.0066\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 3s 66ms/step - loss: -0.0373 - val_loss: -8.1821e-04\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 3s 65ms/step - loss: -0.0415 - val_loss: 0.0057\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 3s 66ms/step - loss: -0.0419 - val_loss: 0.0042\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0441 - val_loss: 0.0075\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0426 - val_loss: 0.0091\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0477 - val_loss: 0.0058\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0465 - val_loss: 0.0077\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 3s 67ms/step - loss: -0.0509 - val_loss: -0.0014\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0501 - val_loss: 0.0106\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0491 - val_loss: 0.0101\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0542 - val_loss: 0.0120\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0499 - val_loss: 0.0068\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0494 - val_loss: 0.0033\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0487 - val_loss: 1.5164e-04\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0522 - val_loss: 0.0072\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0548 - val_loss: 0.0026\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0528 - val_loss: 0.0074\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0555 - val_loss: 0.0119\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0522 - val_loss: 0.0103\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0574 - val_loss: 0.0111\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0542 - val_loss: 0.0126\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0555 - val_loss: 0.0074\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0559 - val_loss: 0.0123\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0557 - val_loss: 0.0066\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0556 - val_loss: 0.0103\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0548 - val_loss: 0.0072\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0568 - val_loss: 0.0024\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0583 - val_loss: 0.0043\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 3s 69ms/step - loss: -0.0601 - val_loss: -0.0039\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0566 - val_loss: 7.2659e-04\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 3s 65ms/step - loss: -0.0562 - val_loss: -0.0048\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0581 - val_loss: 0.0065\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0584 - val_loss: -0.0022\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0609 - val_loss: 1.0745e-04\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0621 - val_loss: 0.0032\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0600 - val_loss: 0.0059\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0593 - val_loss: 0.0031\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0613 - val_loss: 0.0050\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0621 - val_loss: 0.0060\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0608 - val_loss: 0.0052\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0629 - val_loss: 0.0051\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 3s 63ms/step - loss: -0.0627 - val_loss: 0.0091\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: -0.0639 - val_loss: 0.0034\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 5s 115ms/step - loss: -0.0597 - val_loss: 0.0090\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0616 - val_loss: 0.0096\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 3s 61ms/step - loss: -0.0595 - val_loss: 0.0170\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0647 - val_loss: 0.0207\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0617 - val_loss: 0.0155\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0621 - val_loss: 0.0169\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0611 - val_loss: 0.0144\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0625 - val_loss: 0.0095\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0606 - val_loss: 0.0110\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0683 - val_loss: 0.0166\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0635 - val_loss: 0.0132\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 3s 64ms/step - loss: -0.0635 - val_loss: 0.0168\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 3s 62ms/step - loss: -0.0636 - val_loss: 0.0242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2TyTzJUlzhV",
        "outputId": "483d0640-8927-4223-f9c9-6ca2d9680115"
      },
      "source": [
        "print('Training Loss : {}\\nValidation Loss : {}'.format(best_model.evaluate(x_train, ynn_train), best_model.evaluate(x_val, ynn_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6613/6613 [==============================] - 7s 1ms/step - loss: -0.0855\n",
            "1461/1461 [==============================] - 1s 1ms/step - loss: 0.0242\n",
            "Training Loss : -0.08548333495855331\n",
            "Validation Loss : 0.024215780198574066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijh5ovOyms6M",
        "outputId": "40ab2106-0a76-456b-92fe-706b8041b62d"
      },
      "source": [
        "pred_val = best_model.predict(x_val)\n",
        "bet_matrix_val = np.zeros((pred_val.shape))\n",
        "max_bet_val = np.argmax(pred_val, axis=1)\n",
        "n = bet_matrix_val.shape[0]\n",
        "bet_matrix_val[np.arange(n), max_bet_val] = 1\n",
        "profit_val_strat = evaluate_bets(bet_matrix_val, x_val['Odds_Home'], x_val['Odds_Away'], y_val)\n",
        "\n",
        "print(f\"Model achieves profit of ${profit_val_strat.sum():.2f} on the validation sample\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model achieves profit of $-1125.94 on the validation sample\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}